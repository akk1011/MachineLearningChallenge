{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DONE BY KEERTHI KRISHNA AIYAPPAN**\n",
    "\n",
    "Assignment 4: Data Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTING LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATASET A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "_A, y_A = make_classification(n_samples=700, n_features=30, n_informative=9, n_redundant=0, n_repeated=0, n_clusters_per_class=1, flip_y=0.002, random_state=42)\n",
    "\n",
    "\n",
    "data_A = pd.DataFrame(X_A)\n",
    "data_A['target'] = y_A\n",
    "\n",
    "data_A.to_csv('data_A.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: In the above line of code, we have generated Dataset A. Dataset A is created in a way to perform well on logistic regression. The dataset A is linearly separable to some extent. It has less noise (0.002) to favor the linear model of logistic regression. The features and classes have a more straightforward relationship - with zero redundant and repeated features. The n_clusters_per_class was set to 1 to make sure the relationships were close to ideal (linear) for logistic regression to capture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=42)\n",
    "dec_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "pipeline_lr = make_pipeline(StandardScaler(), log_reg)\n",
    "pipeline_dtc = make_pipeline(StandardScaler(), dec_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: In the above line of code, I created pipelines to run both the Logistic Regression and Decision Tree models, I have used a standardscaler() as the only preprocessing step for both the models. As required, I am running both the models in their default parameter settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression on Dataset A: F1 Score (CV) = 0.9571200160254257 | F1 Score (Test) = 0.9324324324324325\n",
      "Decision Tree on Dataset A: F1 Score (CV) = 0.8822884914990178 | F1 Score (Test) = 0.9054054054054054\n"
     ]
    }
   ],
   "source": [
    "data_A = pd.read_csv('data_A.csv')\n",
    "X_A = data_A.drop('target', axis=1)\n",
    "y_A = data_A['target']\n",
    "\n",
    "X_A_train, X_A_test, y_A_train, y_A_test = train_test_split(X_A, y_A, test_size=0.2, random_state=42)\n",
    "\n",
    "scores_lr_A = cross_val_score(pipeline_lr, X_A_train, y_A_train, cv=5, scoring='f1')\n",
    "pipeline_lr.fit(X_A_train, y_A_train)\n",
    "f1_lr_A_test = f1_score(y_A_test, pipeline_lr.predict(X_A_test))\n",
    "\n",
    "\n",
    "scores_dt_A = cross_val_score(pipeline_dtc, X_A_train, y_A_train, cv=5, scoring='f1')\n",
    "pipeline_dtc.fit(X_A_train, y_A_train)\n",
    "f1_dt_A_test = f1_score(y_A_test, pipeline_dtc.predict(X_A_test))\n",
    "\n",
    "print(\"Logistic Regression on Dataset A: F1 Score (CV) =\", scores_lr_A.mean(), \"| F1 Score (Test) =\", f1_lr_A_test)\n",
    "print(\"Decision Tree on Dataset A: F1 Score (CV) =\", scores_dt_A.mean(), \"| F1 Score (Test) =\", f1_dt_A_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: I ran both the models on Data A after splitting it into train and test datasets. We get a F1 score of 0.95 after five folds of cross validation on LR and 0.88 on Decision Tree after five folds of cross validation. Our F1 scores on the test data were 0.93 and 0.90 for LR and DTC respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATASET B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_B, y_B = make_classification(n_samples=20000, n_features=20, n_informative=5, n_redundant=2, n_repeated = 2, n_clusters_per_class=6, flip_y=0.1, random_state=42)\n",
    "\n",
    "data_B = pd.DataFrame(X_B)\n",
    "data_B['target'] = y_B\n",
    "\n",
    "data_B.to_csv('data_B.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: Dataset B is created to favour Decision Trees over Logistic Regression. It has non-linear patterns to exploit the Decision Tree's capability to model complex relationships.It has more noise (0.1), as Decision Trees can handle a higher level of noise and still perform well. It has non-linearly separable classes to some extent, making it harder for logistic regression but manageable for Decision Trees. We set n_clusters_per_class was set to 6, with 2 redundant and repeated features each. Decision Tree also performs well on large datasets, hence n_samples was set to 20000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=42)\n",
    "dec_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "pipeline_lr = make_pipeline(StandardScaler(), log_reg)\n",
    "pipeline_dtc = make_pipeline(StandardScaler(), dec_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: In the above line of code, I created pipelines to run both the Logistic Regression and Decision Tree models, I have used a standardscaler() as the only preprocessing step for both the models. As required, I am running both the models in their default parameter settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression on Dataset B: F1 Score (CV) = 0.6852956508026896 | F1 Score (Test) = 0.6768690416457601\n",
      "Decision Tree on Dataset B: F1 Score (CV) = 0.737155213928792 | F1 Score (Test) = 0.7361216730038023\n"
     ]
    }
   ],
   "source": [
    "data_B = pd.read_csv('data_B.csv')\n",
    "X_B = data_B.drop('target', axis=1)\n",
    "y_B = data_B['target']\n",
    "\n",
    "X_B_train, X_B_test, y_B_train, y_B_test = train_test_split(X_B, y_B, test_size=0.2, random_state=42)\n",
    "\n",
    "scores_lr_B = cross_val_score(pipeline_lr, X_B_train, y_B_train, cv=5, scoring='f1')\n",
    "pipeline_lr.fit(X_B_train, y_B_train)\n",
    "f1_lr_B_test = f1_score(y_B_test, pipeline_lr.predict(X_B_test))\n",
    "\n",
    "scores_dt_B = cross_val_score(pipeline_dtc, X_B_train, y_B_train, cv=5, scoring='f1')\n",
    "pipeline_dtc.fit(X_B_train, y_B_train)\n",
    "f1_dt_B_test = f1_score(y_B_test, pipeline_dtc.predict(X_B_test))\n",
    "\n",
    "print(\"Logistic Regression on Dataset B: F1 Score (CV) =\", scores_lr_B.mean(), \"| F1 Score (Test) =\", f1_lr_B_test)\n",
    "print(\"Decision Tree on Dataset B: F1 Score (CV) =\", scores_dt_B.mean(), \"| F1 Score (Test) =\", f1_dt_B_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: Upon loading and running both the models on the second dataset, we got a F1 score of 0.68 after five folds of cross validation on Logistic Regression. Decision Tree for the same dataset, gave a F1 score of 0.73. F1 scores on the test data were 0.67 and 0.73 on LR and DTC respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: In this assignment, we created two datasets A and B. We did not use feature manipulation to cause a classifier to fail. We encoded our data in a manner that gives both algorithms the best chance they have to do well. For both the datasets, pre-processing was identical across all algorithms. We used default parameter settings - i.e. no hyperparameter tuning to \"force\" a result.  We submitted both the code and the datasets (as csvs).  The datasets were data_A.csv and data_B.csv.\n",
    "We organised the notebook into two different sections - one for each dataset. Each section contains:\n",
    "        - Data generation code\n",
    "        - Data preprocessing as necessary, including scaling, encoding \n",
    "        - Proper model execution with 5-fold cross validation on each model\n",
    "We achieved at least a .02 difference in performance on both datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
